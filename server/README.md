# ðŸ§  Document QA API (FastAPI + ChromaDB + vLLM)

Este serviÃ§o Ã© o **backend** do sistema de perguntas e respostas com base em documentos.  
Ele gerencia o armazenamento de textos no **ChromaDB**, a busca de trechos relevantes e a comunicaÃ§Ã£o com o **modelo de linguagem (vLLM)**.

---

## ðŸš€ Funcionalidades

- Recebe documentos PDF ou TXT via upload.
- Extrai e armazena o conteÃºdo no **ChromaDB**.
- Realiza busca semÃ¢ntica dos trechos mais relevantes para uma pergunta.
- Faz streaming da resposta gerada pelo **modelo LLM (vLLM)**.

---

## ðŸ§© Tecnologias utilizadas

- **FastAPI** â€” Framework web rÃ¡pido e assÃ­ncrono.
- **ChromaDB** â€” Banco vetorial local.
- **LangChain** â€” Para dividir o texto em chunks.
- **PyPDF2** â€” ExtraÃ§Ã£o de texto de PDFs.
- **vLLM / Unsloth** â€” Modelo de linguagem para responder perguntas.

---

## âš™ï¸ InstalaÃ§Ã£o

### 1ï¸âƒ£ Criar ambiente virtual (opcional, mas recomendado)
```bash
python -m venv venv
source venv/bin/activate  # ou venv\Scripts\activate no Windows
````

### 2ï¸âƒ£ Instalar dependÃªncias

```bash
pip install fastapi uvicorn requests PyPDF2 langchain chromadb
```

---

## â–¶ï¸ ExecuÃ§Ã£o

### 3ï¸âƒ£ Iniciar o servidor

```bash
uvicorn server:app --host 0.0.0.0 --port 9000 --reload
```

O servidor iniciarÃ¡ em:

> **[http://localhost:9000](http://localhost:9000)**

---

## ðŸ“¡ Endpoints

### **POST /upload**

Envia um documento (PDF ou TXT) para ser armazenado no ChromaDB.

**Exemplo via `curl`:**

```bash
curl -X POST -F "file=@meu_arquivo.pdf" http://localhost:9000/upload
```

---

### **POST /ask**

Faz uma pergunta com base no documento armazenado.

**Exemplo via `curl`:**

```bash
curl -X POST -F "question=Qual Ã© o objetivo do texto?" http://localhost:9000/ask
```

A resposta serÃ¡ transmitida em **streaming** (texto contÃ­nuo).

---

## ðŸ§  Arquitetura Simplificada

```
+-------------+        +------------+        +-------------+
|  Streamlit  |  --->  |  FastAPI   |  --->  |   vLLM API  |
|   Frontend  |         |  Backend   |        | (localhost) |
+-------------+        +------------+        +-------------+
        |                        |
        |<------ Contexto -------|
        |<----- Resposta --------|
```

---

## ðŸ“ Estrutura

```
server/
â”œâ”€â”€ server.py       # CÃ³digo principal do backend
â”œâ”€â”€ README.md       # Este arquivo
```

---

## ðŸ§© Requisitos adicionais

* Um servidor **vLLM** rodando em `http://localhost:8000/v1/chat/completions`.
* Python 3.9+.

---

## âœ… Exemplo de uso completo

1. Suba o servidor:

   ```bash
   uvicorn server:app --reload --port 9000
   ```
2. FaÃ§a upload de um documento:

   ```bash
   curl -X POST -F "file=@documento.pdf" http://localhost:9000/upload
   ```
3. FaÃ§a uma pergunta:

   ```bash
   curl -X POST -F "question=Qual Ã© o resumo do documento?" http://localhost:9000/ask
   ```

